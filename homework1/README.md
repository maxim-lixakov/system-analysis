# Homework 1 - _Modeling work of Apache Spark_

# Описание Модели Apache Spark в AnyLogic

## 1. Описание Системы

Apache Spark — это быстрая и обобщенная система вычислений для больших данных, предоставляющая высокоуровневые API на Java, Scala, Python и R, а также предоставляющая оптимизированный движок, который поддерживает общие вычислительные графы. Он также поддерживает набор высокоуровневых инструментов, включая [Spark SQL](https://spark.apache.org/sql/) для SQL и структурированных данных, [MLlib](https://spark.apache.org/mllib/) для машинного обучения, [GraphX](https://spark.apache.org/graphx/) для обработки графов и [Structured Streaming](https://spark.apache.org/structured-streaming/) для обработки потоков.

### Основные Компоненты и Принципы Работы
- **YARN**: YARN (Yet Another Resource Negotiator) используется для управления ресурсами и распределения задач по вычислительным узлам.
- **Computing Nodes**: Вычислительные узлы обрабатывают задачи, распределенные YARN, и взаимодействуют друг с другом для обмена данными и результатами.
- **User Tasks**: Задачи пользователей имеют различные атрибуты и параметрыю

### Источники и Обучающие Материалы
- [Официальный Сайт Apache Spark](https://spark.apache.org/)
- [Документация Apache Spark](https://spark.apache.org/docs/latest/)
- [Руководства и Примеры Apache Spark](https://spark.apache.org/examples.html)
- [Туториалы Apache Spark на YouTube](https://www.youtube.com/user/TheApacheSpark)

### Цель Анализа
Анализ работы Apache Spark может помочь в оптимизации производительности, управлении ресурсами и улучшении обработки больших данных, что, в свою очередь, может привести к более эффективному использованию ресурсов и улучшению качества обслуживания пользователей.

### Упрощения и Допущения
При создании модели были сделаны некоторые упрощения и допущения для упрощения процесса моделирования, такие как равномерное распределение задач и использование двух типов узлов с различными характеристиками. Эти упрощения необходимо учитывать при анализе результатов моделирования.

Для более глубокого понимания работы Apache Spark рекомендуется изучить предоставленные выше источники и обучающие материалы.

### Компоненты Модели Системы

- **user_task**: 
  - **Описание**: Задачи от пользователей.
  - **Интенсивность**: 20 задач в минуту.
  - **Атрибуты**:
    - `query`: Сложность запроса.
    - `timeout`: Время ожидания, равномерно распределено между 40 и 60 секундами.
  
- **YARN**: 
  - **Описание**: YARN (Yet Another Resource Negotiator) действует как менеджер ресурсов и распределяет задачи пользователя по доступным вычислительным узлам.
  - **Функции**:
    - **Распределение Задач**: YARN принимает задачи от пользователей и распределяет их по вычислительным узлам на основе доступных ресурсов и других факторов.
    - **Мониторинг Ресурсов**: YARN отслеживает использование ресурсов и доступность узлов для оптимизации распределения задач.
    - **Обработка Сбоев и Таймаутов**: YARN обрабатывает ситуации, когда задача "застряла" или превысила установленный таймаут, и принимает соответствующие меры.
  - **Выходы**: По таймауту и если задача "застряла", YARN может принять решение о прекращении или перезапуске задачи.


- **YARN Output**: 
  - **Описание**: Выбирает узел для выполнения задачи.
  - **Распределение задач**: Равномерное (0.2 для каждого узла).
  

- **Computing Nodes**: 
  - **Описание**: Пять вычислительных узлов, которые обрабатывают задачи, распределенные YARN. Узлы разделены на два типа в зависимости от их характеристик и возможностей.
  - **Тип 1**:
    - **Количество**: Три узла.
    - **Характеристики**: Узлы этого типа в среднем завершают задачу за 1 минуту.
    - **Ядра**: Каждый узел имеет 4 ядра, что позволяет выполнять 4 задачи параллельно.
    - **Действия**: Узлы этого типа принимают задачи от YARN, обрабатывают их, выполняя необходимые трансформации и вычисления, и затем отправляют результаты на агрегацию.
  - **Тип 2**:
    - **Количество**: Два узла.
    - **Характеристики**: Узлы этого типа в среднем завершают задачу за 2 минуты.
    - **Ядра**: Каждый узел имеет 8 ядер, что позволяет выполнять 8 задач параллельно.
    - **Действия**: Подобно узлам типа 1, узлы типа 2 принимают задачи, обрабатывают их, выполняя необходимые трансформации и вычисления, и отправляют результаты на агрегацию.

- **reduce_node**: 
  - **Описание**: Собирает результаты выполнения задач с узлов и формирует итоговый результат.
  - **Время агрегации**: 30 секунд.

- **response**: 
  - **Описание**: Выход системы. Отправляет результаты пользователю.

## Схема Системы

image/video from anylogic

--- 
--- 
--- 
## Сравнение Модели и Реальной Работы Apache Spark

Модель включает в себя несколько аспектов работы Apache Spark, однако существуют некоторые упрощения и различия. Ниже приведены некоторые точки сравнения между моделью и реальной работой Apache Spark:

### 1. **Распределение Задач:**
   - **Модель:** Задачи равномерно распределяются по узлам.
   - **Apache Spark:** Задачи распределяются на основе локальности данных и доступных ресурсов, а не равномерно.

### 2. **Типы Узлов:**
   - **Модель:** Узлы разделены на два типа с различными временами обработки и возможностями параллельной обработки задач.
   - **Apache Spark:** Обычно все узлы в кластере Spark однородны, но Spark может работать с разнородным оборудованием.

### 3. **Выполнение Задач:**
   - **Модель:** Задачи выполняются узлами, а результаты агрегируются `reduce_node`.
   - **Apache Spark:** Задачи выполняются по этапам, и каждый этап выполняет трансформацию или действие над данными. Результаты задач внутри этапа агрегируются с использованием функции reduce.

### 4. **YARN:**
   - **Модель:** YARN представлен как очередь, управляющая распределением задач.
   - **Apache Spark:** YARN — это менеджер кластера, который может использоваться Spark для выделения ресурсов, но Spark также может использовать другие менеджеры кластера, такие как Mesos или свой собственный менеджер кластера.

### 5. **Атрибуты Задач Пользователя:**
   - **Модель:** Задачи пользователя имеют атрибуты, такие как `query` и `timeout`.
   - **Apache Spark:** Задачи пользователя в Spark больше связаны с трансформациями и действиями над RDDs/DataFrames, и обычно у них нет атрибута «timeout».

### 6. **Сбой Задач:**
   - **Модель:** Задачи могут завершиться неудачей, если они ждут больше, чем параметр таймаута.
   - **Apache Spark:** Задачи могут завершиться неудачей по различным причинам, таким как сбой узла, и у Spark есть механизмы для обработки сбоев задач, такие как повторное выполнение задачи на другом узле.

### 7. **Агрегация Задач:**
   - **Модель:** `reduce_node` агрегирует информацию от задач за 30 секунд.
   - **Apache Spark:** Агрегация в Spark обычно выполняется с использованием трансформаций, таких как `reduce` или `aggregate`, и время, которое это занимает, зависит от объема данных и сложности функции агрегации.

### Рекомендации по Улучшению:
1. **Локальность Данных:** Рассмотреть возможность включения локальности данных в распределение задач.
2. **Этапы и Трансформации:** Моделировать выполнение задач по этапам и более явно представлять трансформации и действия.
3. **Отказоустойчивость:** Включить механизмы для обработки сбоев задач и узлов.
4. **Выделение Ресурсов:** Более точно представить, как YARN или другой менеджер кластера выделяет ресурсы для задач.
5. **Атрибуты Задач:** Уточнить атрибуты задач, чтобы они более точно соответствовали видам трансформаций и действий, выполняемых в Spark.

<sup> Создание модели симуляции часто включает в себя создание упрощений и предположений для обеспечения управляемости модели, поэтому нормально, что модель не улавливает все детали реальной системы. Главное — убедиться, что модель точно представляет те аспекты системы, которые важны для ответов на вопросы исследования. </sup>
